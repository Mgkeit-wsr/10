# -*- coding: utf-8 -*-
"""Тест3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/15mUjJ6aFB6QvMXO29LTTDXNt2xUcWzmd
"""

BOT_CONFIG = {"intents": [    
          {'tag':"hello", 
              "example":["Привет!", "Ку", "Хей", "Хэлло","Добрый день", "Добрый вечер ", "Здравствуйте", "Здравствуй", "Welcome!", "Bonjour!"],
              "responces":["Добрый день", "Добрый вечер ", "Здравствуйте", "Здравствуй","Привет!", "Ку", "Хей", "Хэлло","Welcome!", "Bonjour!"]
          },
          {'tag':"bye",
              "example":["Пока", "Увидимся", "До скорого", "Удачи", "До свидания", "До встречи", "Хорошего дня", "Благодарю"],
              "responces":["До свидания", "До встречи", "Хорошего дня", "Благодарю","Пока", "Увидимся", "До скорого", "Удачи"]
                },
          {'tag':"work",
              "example":["сколько дней тебя создавали?","сколько тебе дней?"],
              "responces":["несколько дней назад","относительно недавно","с момента моего создания прошло больше одного дня"]
          },
          {'tag':"weather",
            "example":["какая погода на улице?","что ты можешь сказать о погоде на улице?"],
            "responces":["холодно и преобладает небольшой ветер","ветренно с похолоданием","солнечно c холодным ветром"],
          },
          {'tag':"relax1",
            "example":["чем занимаешься?"],
            "responces":["помогаю пользователям, тебя что-то интересует?", "делаю мир лучше, могу вам чем-то помочь?"]
          },
          {'tag':"affair",
            "example":["как дела?"],
            "responces":["нормально, а у вас?", "отлично, рад знакомству, как у вас?", "хорошо, вы хотели что-то узнать?"]
          },
          {'tag':"relax",
            "example":["куда бы ты полетела отдыхать?","где ты любишь отдыхать?","какое место самое лучшее для отдыха"],
            "responces":["я предпочитаю тёплые страны с жарким климатом, а вы?", "страны Африки прекрасно подходят для отдыха из-за своего тёплого климата, что бы выбрали вы?", "отдых на берегу рядом с морем и жарким климатом оставляет хорошие впечетления, что думаете вы?"]
          },
          {'tag':"relax1",
            "example":["что делать если у меня умерло домашнее животное?", 'у меня умер питомец',"вчера умерла моя кошка", "несколько дней назад умер мой питомец"],
            "responces":["это большая потеря, нельзя расстраивать, нужно продолжать жить дальше","наши питомцы всегда с нами"]
          }, 
            {'tag':"food",
              "example":["какую еду ты считаешь полезной?","какая еда самая полезная?"],
              "responces":["одними из самых полезных продуктов считаются фрукты, овощи и молочные продукты","многие сичтаю что грибы и ягоды повышают иммунетет и укреплчют здоровье человека","во все времена овощи и фрукты считались главным источником витаминов"]
          },
          {'tag':"place",
              "example":["какая самое жаркое место в мире?","какая самая большая пустыня в мире?"],
              "responces":["пустыня Сахара","в пустыне Сахаре почти нет жизни из-за самого сухого климата","самое жаркие и высокие температуры преобладают в пустыне Сахара"]
              }
                ]
}

import nltk
nltk.download('omw-1.4')
from nltk.stem import WordNetLemmatizer
nltk.download('punkt')
nltk.download('wordnet')

lemmatizer = WordNetLemmatizer()
import pickle
import numpy as np

from keras.models import load_model
model = load_model('chatbot_model.h5')

import json
import random
words = pickle.load(open('words.pkl','rb'))
classes = pickle.load(open('classes.pkl','rb'))

def clean_up_sentence(sentence):
    sentence_words = nltk.word_tokenize(sentence)
    sentence_words = [lemmatizer.lemmatize(word.lower()) for word in sentence_words]
    return sentence_words

# return bag of words array: 0 or 1 for each word in the bag that exists in the sentence

def bow(sentence, words, show_details=True):
    # tokenize the pattern
    sentence_words = clean_up_sentence(sentence)
    # bag of words - matrix of N words, vocabulary matrix
    bag = [0]*len(words)
    for s in sentence_words:
        for i,w in enumerate(words):
            if w == s:
                # assign 1 if current word is in the vocabulary position
                bag[i] = 1
                if show_details:
                    print ("found in bag: %s" % w)
    return(np.array(bag))

def predict_class(sentence, model):
    # filter out predictions below a threshold
    p = bow(sentence, words,show_details=False)
    res = model.predict(np.array([p]))[0]
    ERROR_THRESHOLD = 0.25
    results = [[i,r] for i,r in enumerate(res) if r>ERROR_THRESHOLD]
    # sort by strength of probability
    results.sort(key=lambda x: x[1], reverse=True)
    return_list = []
    for r in results:
        return_list.append({"intent": classes[r[0]], "probability": str(r[1])})
    return return_list

def getResponse(ints, intents_json):
    tag = ints[0]['intent']
    list_of_intents = intents_json['intents']
    for i in list_of_intents:
        if(i['tag']== tag):
            result = random.choice(i['responces'])
            break
    return result

def chatbot_response(msg):
    ints = predict_class(msg, model)
    res = getResponse(ints, BOT_CONFIG)
    return res